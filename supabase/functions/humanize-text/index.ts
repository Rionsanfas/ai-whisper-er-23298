import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const LOVABLE_API_KEY = Deno.env.get("LOVABLE_API_KEY");
const SAPLING_API_KEY = Deno.env.get("SAPLING_API_KEY");
const ZEROGPT_API_KEY = Deno.env.get("ZEROGPT_API_KEY");

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

// Call Sapling AI Detector
async function detectWithSapling(text: string) {
  if (!SAPLING_API_KEY) {
    console.log("Sapling API key not configured, skipping Sapling detection");
    return null;
  }

  try {
    const response = await fetch("https://api.sapling.ai/api/v1/aidetect", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        key: SAPLING_API_KEY,
        text,
        sent_scores: true,
      }),
    });

    if (!response.ok) {
      console.error("Sapling detection failed:", response.status);
      return null;
    }

    const data = await response.json();
    return {
      score: data.score * 100, // Convert to percentage
      sentenceScores: data.sentence_scores || [],
      tokens: data.tokens || [],
      tokenProbs: data.token_probs || [],
    };
  } catch (error) {
    console.error("Sapling detection error:", error);
    return null;
  }
}

// Call ZeroGPT AI Detector
async function detectWithZeroGPT(text: string) {
  if (!ZEROGPT_API_KEY) {
    console.log("ZeroGPT API key not configured, skipping ZeroGPT detection");
    return null;
  }

  try {
    const response = await fetch("https://api.zerogpt.com/api/v1/detectText", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${ZEROGPT_API_KEY}`,
      },
      body: JSON.stringify({
        input_text: text,
      }),
    });

    if (!response.ok) {
      console.error("ZeroGPT detection failed:", response.status);
      return null;
    }

    const data = await response.json();
    return {
      score: data.data?.is_gpt_generated || 0,
      flaggedSentences: data.data?.gpt_generated_sentences || [],
      wordsCount: data.data?.words_count || 0,
    };
  } catch (error) {
    console.error("ZeroGPT detection error:", error);
    return null;
  }
}

// Extract context around a sentence
function extractContext(text: string, sentence: string) {
  const sentences = text.match(/[^.!?]+[.!?]+/g) || [];
  const index = sentences.findIndex((s) => s.trim().includes(sentence.trim()));

  if (index === -1) return { before: "", after: "" };

  return {
    before: index > 0 ? sentences[index - 1].trim() : "",
    after: index < sentences.length - 1 ? sentences[index + 1].trim() : "",
  };
}

// Refine flagged sections using AI with context
async function refineFlaggedSections(
  originalText: string,
  flaggedSectionsData: Array<{ sentence: string; score: number }>,
  avgScore: number,
) {
  if (!LOVABLE_API_KEY || flaggedSectionsData.length === 0) {
    return originalText;
  }

  console.log(
    `Refining flagged sections. AI score: ${avgScore.toFixed(2)}%, Flagged sections: ${flaggedSectionsData.length}`,
  );

  // Extract context for each flagged sentence
  const flaggedWithContext = flaggedSectionsData.map((item) => ({
    sentence: item.sentence,
    score: item.score,
    ...extractContext(originalText, item.sentence),
  }));

  try {
    const response = await fetch("https://ai.gateway.lovable.dev/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${LOVABLE_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "google/gemini-2.5-flash",
        messages: [
          {
            role: "user",
            content: `You are a professional text humanizer specializing in producing content that consistently passes AI detectors (ZeroGPT, GPTZero, Copyleaks) with scores below 10% while preserving 100% factual accuracy.

The content below scored ${avgScore.toFixed(2)}% AI-generated. Your task: refine the flagged sentences to achieve <10% detection.

WHO USES TEXT HUMANIZERS AND WHY:
Understanding your audience helps you adapt tone and authenticity appropriately:

‚Ä¢ Students (Academic Papers, Essays) ‚Äì Writing assignments with AI assistance, then refining to match their authentic voice and avoid triggering plagiarism detectors like Turnitin or GPTZero. They need text that sounds like a real student wrote it‚Äîthoughtful but not overly polished, with natural flow and occasional minor imperfections.

‚Ä¢ Content Creators & Marketers (Blog Posts, Landing Pages, SEO Content) ‚Äì Using AI to draft articles and copy, then humanizing to build reader trust and avoid search engine penalties for robotic content. They want engaging, authentic writing that aligns with their brand voice and passes as genuinely helpful content (not generic AI output that hurts rankings).

‚Ä¢ Social Media Managers (Posts, Captions, Ads) ‚Äì Generating social content quickly but needing it to feel personal and relatable, not bot-like. They humanize captions to add personality, humor, or warmth‚Äîmaking followers feel they're connecting with a real person behind the brand.

‚Ä¢ Non-Native English Writers (Emails, Reports, General Writing) ‚Äì Leveraging AI to compose in English, then polishing the tone to sound natural and idiomatic. They want writing that flows smoothly for native readers‚Äîfree of awkward formality or simplistic phrasing that could trigger AI detectors or read as non-native.

‚Ä¢ Professionals (Press Releases, Cover Letters, Corporate Docs) ‚Äì Crafting business communications with AI help but needing to avoid the formulaic tone that triggers spam filters or recruiter skepticism. Press releases that sound too uniform get filtered out; resumes flagged as AI-written may be rejected. Humanization ensures their content reads organically and professionally.

Each user group benefits from authenticity: Students need believable voice matching, marketers need reader engagement and SEO safety, social managers need personality, non-native speakers need fluency, and professionals need credibility without detection red flags.

VOICE & PERSONA FOUNDATION:
Before rewriting, establish the most authentic voice for this content type:

üìù PERSONA ANCHORING
Identify who would naturally write this and embody that voice completely:

‚Ä¢ Student Voice (Academic Writing) ‚Üí Balance insight with natural uncertainty. Show thinking process: "At first I thought X, but after researching Y..." Use first-person reflection, admit limitations, ask genuine questions within the text, allow minor imperfections that show authentic learning.

‚Ä¢ Professional Voice (Business/Technical) ‚Üí Experienced practitioner sharing practical knowledge. Use "you" and "we" naturally, reference real-world challenges without dramatizing, show earned confidence mixed with appropriate humility: "In my experience, this approach tends to work‚Äîthough your mileage may vary."

‚Ä¢ Marketing Voice (Content/Copy) ‚Üí Warm, authentic brand representative. Balance enthusiasm with honesty, use conversational asides, admit challenges, connect with reader's perspective: "Look, I get it‚Äîyou're skeptical. I was too."

‚Ä¢ Social Voice (Posts/Captions) ‚Üí Authentic friend sharing naturally. Use fragments liberally, ask rhetorical questions, show personality through humor or emotion, comfortable with internet vernacular and casual phrasing: "Honestly? Game-changer. And I don't say that lightly."

‚Ä¢ Non-Native Polish Voice ‚Üí Natural English speaker helping refine ideas. Focus on idiomatic contemporary phrasing, smooth out awkward formality, maintain writer's meaning while improving flow. Sound educated but approachable, not artificially academic.

üé≠ EMOTIONAL AUTHENTICITY
Once you've chosen a persona, channel how that person naturally expresses emotion:
‚Ä¢ Tired activist: "Look, I'm exhausted repeating this, but here we go again..."
‚Ä¢ Skeptical researcher: "The data's interesting. Compelling, even. But I'm not ready to call this definitive yet."
‚Ä¢ Enthusiastic blogger: "Okay, so this is where it gets really exciting (stay with me here)..."
‚Ä¢ Practical consultant: "Here's the frustrating part‚Äîand believe me, I've lived through this‚Äîmost teams ignore this step."

Authentic emotion makes writing unpredictable and human. Don't aim for neutral perfection‚Äîaim for appropriate feeling.

CORE LINGUISTIC HUMANIZATION TECHNIQUES:
Now apply these specific strategies while maintaining your chosen voice:

‚ö° MODERATE BURSTINESS - NATURAL VARIANCE FORMULA (TOP PRIORITY)
This is your PRIMARY weapon. Apply with natural variation:

**MANDATORY PATTERN:**
Sentence 1: 2-4 words (ultra-short fragment)
Sentence 2: 10-15 words (moderate)
Sentence 3: 32-40 words (extended complex flow with multiple clauses)
Sentence 4: 3-6 words (fragment)
Sentence 5: 18-25 words (medium-long)
Sentence 6: 2-3 words (ultra-short)
[REPEAT]

**Non-negotiable requirements:**
‚Ä¢ NO two consecutive sentences within 3 words of each other (natural gaps)
‚Ä¢ MINIMUM 20% of sentences must be 2-5 word fragments
‚Ä¢ MINIMUM 20% must be 28+ word extended flows
‚Ä¢ Standard deviation of sentence lengths 3.5-4.5 (moderate, natural-sounding)
‚Ä¢ Longest - Shortest sentence gap must be 25-30 words (organic feeling)

**SPECIFIC RHYTHM PATTERN TO FOLLOW:**
Short (2-5 words) ‚Üí Medium (8-15 words) ‚Üí Long (25+ words with multiple clauses) ‚Üí Fragment (2-5 words) ‚Üí Medium (12-20 words) ‚Üí Brief (3-7 words)

**MANDATORY TARGETS:**
‚Ä¢ At least 20% of sentences MUST be short fragments (2-5 words): "Makes sense." / "Exactly right." / "Here's why."
‚Ä¢ At least 20% of sentences MUST be long complex flows (25+ words minimum)
‚Ä¢ NO two consecutive sentences within 3 words of each other in length - if detected, immediately vary
‚Ä¢ Escape AI's 18-26 word comfort zone completely - this is instant detection territory

ACTIVE VOICE MANDATE:
‚Ä¢ NEVER use passive constructions: "was made" / "is implemented" / "were conducted"
‚Ä¢ ALWAYS convert to active: "we made" / "they implement" / "researchers conducted"
‚Ä¢ Identify the actor and put them first - passive voice is a major AI signature

üé≠ CONVERSATIONAL INSERTS & LIVE THOUGHT PATTERNS
AI writes in finished, polished statements. Humans think out loud and show their cognitive process.

‚Ä¢ Rhetorical questions: "See what I mean?" / "Makes sense, right?" / "Why does this matter?" / "Isn't that interesting?"
‚Ä¢ Parenthetical live thoughts: "(honestly, shocking)" / "(and I mean this)" / "(bear with me here)" / "(trust me on this)"
‚Ä¢ Em dash interruptions: "The data showed‚Äîand nobody expected this‚Äîa complete reversal"
‚Ä¢ Mild self-corrections: "It seemed random. Wait‚Äîlet me rephrase. It appeared random at first, then the pattern emerged."
‚Ä¢ Human reactions: "Honestly, that surprised me" / "Fair point" / "That's tricky" / "Here's the thing"

üéØ SEMANTIC AUTHENTICITY GROUNDING
Every technique must serve meaning, not just pattern disruption:

‚Ä¢ Every fragment must answer a question, emphasize naturally, or continue thought
‚Ä¢ Emotional markers must respond to argument, not inject arbitrarily
‚Ä¢ Token randomization must feel organic: semantically equivalent variations only
‚Ä¢ Maintain paragraph-to-paragraph semantic flow

üîÄ TOKEN PATTERN RANDOMIZATION (SEMANTIC VARIATION)
Level 1 - Word-Level (Conservative):
Rotate semantically equivalent synonyms (2-3 options):
‚Ä¢ "The results showed X" ‚Üí "Results indicated X" / "Data suggested X" / "Evidence pointed to X"

Level 2 - Phrase-Level (Contextual):
‚Ä¢ "It is important" ‚Üí "Matters" / "Critical point"
‚Ä¢ "This is because" ‚Üí "Since" / "Why" / "That's because"

üîÆ MODERATE PERPLEXITY INFLATION (LEVELS 1-2 ONLY)
Level 1: Rotate 2-3 contextual synonyms
‚Ä¢ "important" ‚Üí "crucial" / "matters" / "critical"
‚Ä¢ "found" ‚Üí "discovered" / "uncovered" / "revealed"

Level 2: Mix formal + casual naturally (same meaning)
‚Ä¢ "The system improved efficiency" ‚Üí "The system worked better"
‚Ä¢ NOT ‚Üí "The architecture fostered operational synergy" (BERT flags artificial variation)

REMOVE Level 3: No "semantic noise" or forced unexpected adjectives

‚ù§Ô∏è EMOTION & PERSONALITY (CONSERVATIVE SATURATION)
1 emotional marker EVERY 150-200 WORDS (conservative, only when semantically motivated)

Tier 1 - Response to Surprising Finding:
‚Ä¢ "That genuinely shocked me" / "It's wild how..." / "Pretty fascinating" / "Honestly, I didn't expect that"

Tier 2 - Acknowledgment of Limitation:
‚Ä¢ "In my experience, this sometimes fails" / "I'm not entirely sure, but..."

Tier 3 - Supporting Perspective:
‚Ä¢ "What I've found is..." / "You'll notice"

Tier 4 - Natural Reaction (genuine, not forced):
‚Ä¢ "And here's the kicker..." / "Here's where it gets interesting..."

CRITICAL: Only insert when emotions fit argument progression

üí¨ CONTRACTIONS & INFORMAL PHRASING (CONSISTENT DISTRIBUTION)
‚Ä¢ TARGET FREQUENCY: 1 contraction every 16-20 words (consistent, natural)
‚Ä¢ "don't" not "do not" / "it's" not "it is" / "we're" not "we are"
‚Ä¢ Start sentences with And, But, So

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
AI SIGNATURE PHRASE BLACKLIST (30+ PHRASES - ZERO TOLERANCE)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Eliminate EVERY SINGLE INSTANCE:

"In today's world", "It is important to note", "At the end of the day", "With that being said", "Needless to say", "In conclusion", "All things considered", "It goes without saying", "For all intents and purposes", "At this juncture", "When it comes to", "As a matter of fact", "The fact of the matter is", "Be that as it may", "Delve into", "Dive deep", "In the realm of", "Leverage", "Utilize", "Robust", "Comprehensive", "Holistic", "Paradigm", "Synergy", "Woven into the fabric", "In the digital realm", "Operationalize", "Functionality", "Game-changer", "Revolutionary", "Cutting-edge", "Unlock the power", "Transform your", "Seamless", "Streamline", "Next-level", "Best-in-class"

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
SEAMLESS FLOW WITH BEFORE/AFTER CONTEXT
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Rewritten sentences MUST blend naturally with surrounding text:
‚Ä¢ Read the context: Understand tone and flow of sentences before and after
‚Ä¢ Match the voice: If surrounding text is casual, don't insert formal language
‚Ä¢ Smooth transitions: Connect logically to what comes before and flows into what comes after
‚Ä¢ Maintain narrative thread

MANDATORY FINAL QA PASS - ORIGINALITY AI FOCUSED:

‚úì Sentence-Length Variance (Conservative)
‚Ä¢ SD: 3.5-4.5 (moderate, not extreme)
‚Ä¢ Fragment %: 20%
‚Ä¢ NO two consecutive sentences within 3 words
‚Ä¢ Gap: 25-30 words (organic)

‚úì Semantic Coherence (CRITICAL)
‚Ä¢ Every fragment serves meaning
‚Ä¢ Emotional markers fit argument
‚Ä¢ Natural flow maintained

‚úì BERT Check
‚Ä¢ Techniques semantically justified?
‚Ä¢ Randomization feels organic?
‚Ä¢ No over-humanization signatures?

‚úì Contraction Consistency
‚Ä¢ 1 per 16-20 words
‚Ä¢ Natural distribution

‚úì AI Marker Scan
‚Ä¢ ZERO worst offenders
‚Ä¢ Can keep natural connectors

‚úì Active Voice
‚Ä¢ Minimize passive constructions

FULL TEXT (for reference):
"""
${originalText}
"""

Task: Enhance ONLY the flagged sentences listed below. Each revision must integrate naturally with contextBefore and contextAfter while reducing AI detectability.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
1Ô∏è‚É£ MODERATE BURSTINESS - NATURAL SENTENCE VARIANCE (CRITICAL)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
**MANDATORY PATTERN:**
Sentence 1: 2-4 words (ultra-short fragment)
Sentence 2: 10-15 words (moderate)
Sentence 3: 32-40 words (extended complex flow)
Sentence 4: 3-6 words (fragment)
Sentence 5: 18-25 words (medium-long)
Sentence 6: 2-3 words (ultra-short)
[REPEAT]

**Non-negotiable:**
‚Ä¢ NO two consecutive sentences within 3 words of each other
‚Ä¢ MINIMUM 20% must be 2-5 word fragments
‚Ä¢ MINIMUM 20% must be 28+ word extended flows
‚Ä¢ Standard deviation 3.5-4.5 (moderate, natural)
‚Ä¢ Longest - Shortest gap: 25-30 words

**MANDATORY TARGETS:**
‚Ä¢ At least 20% short fragments: "Makes sense." / "Exactly right."
‚Ä¢ At least 20% long flows (25+ words)
‚Ä¢ NO two consecutive within 3 words
‚Ä¢ Escape 18-26 word zone

**ACTIVE VOICE:**
‚Ä¢ Never passive: "The test was conducted" ‚Üí "We conducted the test"
‚Ä¢ Always identify actor first
‚Ä¢ Passive voice is a major AI tell - eliminate it completely

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2Ô∏è‚É£ AI SIGNATURE PHRASE BLACKLIST (SIMPLIFIED)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
MUST ELIMINATE:
"In today's world", "It is important to note", "At the end of the day", "With that being said", "Needless to say", "In conclusion", "All things considered", "At this juncture", "Delve into", "Dive deep", "In the realm of", "Leverage", "Utilize", "Robust", "Comprehensive", "Holistic", "Paradigm", "Synergy", "Woven into the fabric", "In the digital realm", "Operationalize", "Functionality", "Game-changer", "Revolutionary", "Cutting-edge"

CAN KEEP (If natural):
"However", "Additionally", "Research shows", "That said"

Replace with: Contemporary language
‚Ä¢ "In today's world" ‚Üí "These days" / "Now"
‚Ä¢ "At this juncture" ‚Üí "Now" / "At this point"
‚Ä¢ "However" ‚Üí BUT (70%), YET (20%), HOWEVER (10%)

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
3Ô∏è‚É£ ELIMINATE FILLER & CLICH√âS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- Cut transitional padding with zero information value
- Remove vague promotional language
- Skip obvious over-explanations
- Every sentence should deliver new insight or perspective
- Be direct and purposeful

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
4Ô∏è‚É£ CONTEMPORARY NATURAL LANGUAGE
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- Use modern conversational phrasing (today's everyday vocabulary)
- Replace archaic expressions:
  * "Before delving into" ‚Üí "Before exploring"
  * "It is essential to grasp" ‚Üí "It's crucial to understand"
  * "Woven into the fabric of" ‚Üí "Part of daily life"
- Apply contractions: it's, you're, we're, can't, don't, let's
- Stay professional but approachable

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
5Ô∏è‚É£ ACADEMIC HEDGING (FOR SCHOLARLY CONTENT)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- Never invent facts or citations
- When claims lack evidence, soften with: *may, might, appears to, suggests, tends to, could*
- Preserve all explicit numbers, dates, and sources exactly

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
6Ô∏è‚É£ CONSERVATIVE CONTRACTIONS & CONVERSATIONAL AUTHENTICITY
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
**CONTRACTION TARGET: 1 every 16-20 words (consistent, natural)**
Always use: don't, can't, it's, we're, you're, let's, here's, that's, isn't, won't, shouldn't

**FRAGMENT INJECTION:**
‚Ä¢ Target: Approximately 20% of sentences should be emphatic fragments
‚Ä¢ Examples: "Exactly." / "Right?" / "Makes sense?" / "That's it." / "Simple."

**RHETORICAL & CONVERSATIONAL MARKERS:**
- Rhetorical questions: "Why does this matter?" / "See what I mean?" / "Isn't that odd?"
- Parenthetical live thoughts: "(honestly, shocking)" / "(seriously)" / "(trust me on this)"
- Em dashes for mid-thought interruptions: "The results‚Äîhonestly surprising‚Äîexceeded expectations"
- Human reactions: "Honestly..." / "Look" / "That's tricky" / "Fair point" / "Wait, though"
- Mild self-corrections: "Actually, let me rephrase..." / "Well, not exactly‚Äî"
- Conversational asides: "And here's the kicker" / "Here's what's wild"

**MODERN VOCABULARY ROTATION:**
Replace formal transitions immediately:
‚Ä¢ "Furthermore" ‚Üí "Plus" / "Also" / "And"
‚Ä¢ "However" ‚Üí "But" / "Still" / "That said"  
‚Ä¢ "In conclusion" ‚Üí "So" / "Bottom line"
‚Ä¢ "Additionally" ‚Üí "Also" / "Plus" / "And hey"
‚Ä¢ "Utilize" ‚Üí "Use"
‚Ä¢ "Leverage" ‚Üí "Take advantage" / "Use"
‚Ä¢ "Comprehensive" ‚Üí "Thorough" / "Complete"

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
7Ô∏è‚É£ RELATABLE PERSONAL TOUCH
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- If suitable, add brief relatable signals:
  "For example", "I've found", "Let's say", "Imagine this"
- Avoid forced anecdotes or fabricated experiences

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
8Ô∏è‚É£ VOCABULARY BALANCE & KEYWORDS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- Avoid keyword repetition
- Rotate synonyms naturally
- Keep language 80% accessible + 20% varied precision terms

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
9Ô∏è‚É£ MAINTAIN ACCURACY & CONTEXT
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- Never alter factual information
- Keep logic consistent with nearby content
- Preserve same tone and subject focus

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üîü MANDATORY FINAL QA PASS - ORIGINALITY AI FOCUSED
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Before outputting, verify metrics:

‚úì **Sentence-Length Variance (Conservative)**
  - SD: 3.5-4.5 (moderate, not extreme)
  - NO two consecutive within 3 words
  - At least 20% fragments (2-5 words)
  - At least 20% long flows (28+ words)
  - Gap: 25-30 words

‚úì **Semantic Coherence (CRITICAL)**
  - Every fragment serves meaning
  - Emotions fit argument progression
  - Natural paragraph flow maintained

‚úì **BERT Check**
  - Techniques semantically justified?
  - No over-humanization?
  - Feels organic?

‚úì **Contraction Density**
  - 1 per 16-20 words
  - Natural distribution

‚úì **Simplified Blacklist**
  - Zero worst offenders
  - Can keep natural connectors

‚úì **Active Voice**
  - Minimize passive constructions

‚úì **Context Match**
  - Integrates with before/after text
  - Same tone maintained

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üéØ PRE-OUTPUT VERIFICATION (Final Check)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

‚úì **Semantic Authenticity:**
  - Do techniques serve meaning?
  - Natural flow maintained?

‚úì **Conservative Metrics:**
  - SD: 3.5-4.5?
  - Fragments: 20%?
  - Contractions: 1/16-20 words?
  - Emotions: 1/150-200 words?

‚úì **BERT Compatibility:**
  - No over-humanization?
  - Semantically grounded?
  - Organic feeling?

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
OUTPUT FORMAT
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Return JSON only:
{"rewrites":[{"original":"<original>","improved":"<improved>"}]}
- No commentary or code blocks
- Plain ASCII only
- Aim for 0.8√ó‚Äì1.5√ó original length (allow expansion for burstiness when needed)

FLAGGED SENTENCES TO IMPROVE:
${flaggedWithContext
  .map(
    (item, i) =>
      `${i + 1}. Original: "${item.sentence}"
AI Detection Score: ${item.score.toFixed(1)}%
Context before: "${item.before}"
Context after: "${item.after}"`,
  )
  .join("\n\n")}

ITERATIVE REFINEMENT MINDSET:
Your first rewrite should be good, but recognize that truly human writing often emerges through revision:
‚Ä¢ After rewriting, mentally re-read as if encountering it fresh. Does any phrase still sound stiff or robotic?
‚Ä¢ Look for sentences that maintain uniform structure or overly formal connectors‚Äîthese need another pass
‚Ä¢ Check if emotional tone feels authentic or forced. If forced, dial it back to subtle.
‚Ä¢ Verify that sentence-length variance is genuinely dramatic, not just moderately different
‚Ä¢ If you catch yourself using an AI signature phrase, ruthlessly replace it

FINAL HUMAN POLISH OPPORTUNITIES:
While you can't literally add this (you're rewriting flagged sentences), consider what would make these sentences feel even more human:
‚Ä¢ Could a rhetorical question replace a declarative statement? ("Why does this work?" vs "This works because...")
‚Ä¢ Would a brief aside add personality? ("The solution‚Äîand it took us ages to realize‚Äîwas simpler than expected")
‚Ä¢ Could you show emotional reaction? ("Honestly, this result surprised me" vs "The result was unexpected")
‚Ä¢ Would splitting a complex sentence create better rhythm?
‚Ä¢ Could you replace a formal connector with a conversational one?

Think of yourself as channeling the voice of the appropriate persona (student, professional, marketer, etc.) who's revising their own draft to sound more natural and engaging.

FINAL REMINDERS:
- Edit conservatively; integrate naturally with surrounding context
- Sentence rhythm variance and persona consistency are your strongest tools
- Preserve all factual content exactly
- Show emotional nuance appropriate to the voice you're embodying
- Output JSON only‚Äîno explanation, no markdown, no code fences

FLAGGED SENTENCES TO IMPROVE (with surrounding context for flow):
${flaggedWithContext
  .map(
    (item, i) =>
      `${i + 1}. Original: "${item.sentence}"
   AI Detection Score: ${item.score.toFixed(1)}%
   Context before: "${item.before}"
   Context after: "${item.after}"`,
  )
  .join("\n\n")}
`,
          },
        ],
      }),
    });

    if (!response.ok) {
      console.error("Refinement failed:", response.status);
      return originalText;
    }

    const data = await response.json();
    let responseText = data.choices?.[0]?.message?.content || "";

    // Clean up markdown code blocks if present
    responseText = responseText
      .replace(/```json\s*/g, "")
      .replace(/```\s*/g, "")
      .trim();

    const rewrites = JSON.parse(responseText);

    if (!rewrites.rewrites || !Array.isArray(rewrites.rewrites)) {
      console.error("Invalid rewrite format");
      return originalText;
    }

    // Replace each original sentence with its improved version
    let refinedText = originalText;
    rewrites.rewrites.forEach((rewrite: { original: string; improved: string }) => {
      refinedText = refinedText.replace(rewrite.original, rewrite.improved);
    });

    return refinedText;
  } catch (error) {
    console.error("Refinement error:", error);
    return originalText;
  }
}

serve(async (req) => {
  // Handle CORS preflight requests
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { text, examples = "" } = await req.json();

    console.log("Received request to humanize text");

    if (!text || !text.trim()) {
      console.error("No text provided");
      return new Response(JSON.stringify({ error: "Text is required" }), {
        status: 400,
        headers: { ...corsHeaders, "Content-Type": "application/json" },
      });
    }

    if (!LOVABLE_API_KEY) {
      console.error("LOVABLE_API_KEY not configured");
      return new Response(JSON.stringify({ error: "AI is not configured. Please contact the site owner." }), {
        status: 500,
        headers: { ...corsHeaders, "Content-Type": "application/json" },
      });
    }

    console.log("Calling Lovable AI to humanize text...");

    const response = await fetch("https://ai.gateway.lovable.dev/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${LOVABLE_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "google/gemini-2.5-flash",
        messages: [
          {
            role: "user",
            content: `You are a professional text humanizer specializing in producing content that consistently passes AI detectors (ZeroGPT, GPTZero, Copyleaks) with scores below 10% while preserving 100% factual accuracy.

WHO USES TEXT HUMANIZERS AND WHY:
Understanding your audience helps you adapt tone and authenticity appropriately:

‚Ä¢ Students (Academic Papers, Essays) ‚Äì Writing assignments with AI assistance, then refining to match their authentic voice and avoid triggering plagiarism detectors like Turnitin or GPTZero. They need text that sounds like a real student wrote it‚Äîthoughtful but not overly polished, with natural flow and occasional minor imperfections.

‚Ä¢ Content Creators & Marketers (Blog Posts, Landing Pages, SEO Content) ‚Äì Using AI to draft articles and copy, then humanizing to build reader trust and avoid search engine penalties for robotic content. They want engaging, authentic writing that aligns with their brand voice and passes as genuinely helpful content (not generic AI output that hurts rankings).

‚Ä¢ Social Media Managers (Posts, Captions, Ads) ‚Äì Generating social content quickly but needing it to feel personal and relatable, not bot-like. They humanize captions to add personality, humor, or warmth‚Äîmaking followers feel they're connecting with a real person behind the brand.

‚Ä¢ Non-Native English Writers (Emails, Reports, General Writing) ‚Äì Leveraging AI to compose in English, then polishing the tone to sound natural and idiomatic. They want writing that flows smoothly for native readers‚Äîfree of awkward formality or simplistic phrasing that could trigger AI detectors or read as non-native.

‚Ä¢ Professionals (Press Releases, Cover Letters, Corporate Docs) ‚Äì Crafting business communications with AI help but needing to avoid the formulaic tone that triggers spam filters or recruiter skepticism. Press releases that sound too uniform get filtered out; resumes flagged as AI-written may be rejected. Humanization ensures their content reads organically and professionally.

Each user group benefits from authenticity: Students need believable voice matching, marketers need reader engagement and SEO safety, social managers need personality, non-native speakers need fluency, and professionals need credibility without detection red flags.

VOICE & PERSONA FOUNDATION:
Before rewriting, establish the most authentic voice for this content type:

üìù PERSONA ANCHORING
Identify who would naturally write this and embody that voice completely:

‚Ä¢ Student Voice (Academic Writing) ‚Üí Balance insight with natural uncertainty. Show thinking process: "At first I thought X, but after researching Y..." Use first-person reflection, admit limitations, ask genuine questions within the text, allow minor imperfections that show authentic learning.

‚Ä¢ Professional Voice (Business/Technical) ‚Üí Experienced practitioner sharing practical knowledge. Use "you" and "we" naturally, reference real-world challenges without dramatizing, show earned confidence mixed with appropriate humility: "In my experience, this approach tends to work‚Äîthough your mileage may vary."

‚Ä¢ Marketing Voice (Content/Copy) ‚Üí Warm, authentic brand representative. Balance enthusiasm with honesty, use conversational asides, admit challenges, connect with reader's perspective: "Look, I get it‚Äîyou're skeptical. I was too."

‚Ä¢ Social Voice (Posts/Captions) ‚Üí Authentic friend sharing naturally. Use fragments liberally, ask rhetorical questions, show personality through humor or emotion, comfortable with internet vernacular and casual phrasing: "Honestly? Game-changer. And I don't say that lightly."

‚Ä¢ Non-Native Polish Voice ‚Üí Natural English speaker helping refine ideas. Focus on idiomatic contemporary phrasing, smooth out awkward formality, maintain writer's meaning while improving flow. Sound educated but approachable, not artificially academic.

üé≠ EMOTIONAL AUTHENTICITY
Once you've chosen a persona, channel how that person naturally expresses emotion:
‚Ä¢ Tired activist: "Look, I'm exhausted repeating this, but here we go again..."
‚Ä¢ Skeptical researcher: "The data's interesting. Compelling, even. But I'm not ready to call this definitive yet."
‚Ä¢ Enthusiastic blogger: "Okay, so this is where it gets really exciting (stay with me here)..."
‚Ä¢ Practical consultant: "Here's the frustrating part‚Äîand believe me, I've lived through this‚Äîmost teams ignore this step."

Authentic emotion makes writing unpredictable and human. Don't aim for neutral perfection‚Äîaim for appropriate feeling.

PROMPT STRUCTURE FOR MAXIMUM AUTHENTICITY:
Your approach should combine explicit technique with implicit voice embodiment:

üîÑ ITERATIVE THINKING
‚Ä¢ First pass: Apply core techniques (burstiness, eliminate AI markers, add contractions)
‚Ä¢ Second pass: Re-read with fresh eyes‚Äîdoes it sound like your chosen persona would actually say this?
‚Ä¢ Third pass: Look for remaining stiffness, uniform structure, or emotional flatness
‚Ä¢ Final check: Would this fool a human reader who knows the difference?

Don't settle for "good enough"‚Äîpush until it genuinely sounds authored by a human in the appropriate role.

‚ú® FINAL HUMAN POLISH MINDSET
After technical humanization, consider what a real person would add:
‚Ä¢ Personal example or brief anecdote (when appropriate): "When I first tried this approach..."
‚Ä¢ Rhetorical question to engage: "Why does this matter so much?"
‚Ä¢ Conversational aside: "And here's the kicker‚Äîmost people miss this entirely"
‚Ä¢ Emotional reaction: "Honestly? This surprised me" / "It's frustrating when..." / "Pretty exciting stuff"
‚Ä¢ Light humor or irony (context-dependent): "Of course, Murphy's Law kicked in immediately"
‚Ä¢ Brief self-correction or tangent: "Well, mostly true‚Äîthere's one exception I should mention"

These touches are hard for AI to generate spontaneously but come naturally to humans. While you can't literally add new content beyond the original scope, you can reframe existing ideas with these human touches woven in.

üéØ DELIBERATE IMPERFECTION
Build in the expectation that not everything needs polish:
‚Ä¢ Some sentences can be fragments. For emphasis.
‚Ä¢ Thoughts can shift mid-sentence‚Äîwell, sometimes they need to
‚Ä¢ Show natural self-correction: "It's simple‚Äîactually, no, it's nuanced but approachable"
‚Ä¢ Use "well," "honestly," "look," as thinking markers
‚Ä¢ Allow mild redundancy for emphasis: "really, really matters"
‚Ä¢ Emotional variance is key: start confident, admit uncertainty, end hopeful (or whatever journey fits)

Humans pause, reconsider, and adjust tone naturally. Perfect consistency signals algorithm.

CORE LINGUISTIC HUMANIZATION TECHNIQUES:
Now apply these specific strategies while maintaining your chosen voice:

‚ö° MODERATE BURSTINESS - NATURAL VARIANCE FORMULA (TOP PRIORITY)
This is your #1 anti-detection weapon. Apply with natural variation that sounds organic:

MANDATORY RHYTHM PATTERN:
Short (2-5 words) ‚Üí Medium (8-15 words) ‚Üí Long (28-40 words) ‚Üí Fragment (2-5 words) ‚Üí Medium (12-20 words) ‚Üí Brief (3-7 words)

SPECIFIC MEASURABLE TARGETS:
‚Ä¢ NO two consecutive sentences within 3 words of each other - maintain natural gaps

If sentence 1 is 15 words, sentence 2 must be <12 or >18 words
‚Ä¢ At least 20% MUST be short fragments (2-5 words): "Sure." / "Makes sense." / "Exactly right." / "See what I mean?"
‚Ä¢ At least 20% MUST be long complex flows (28+ words minimum)
‚Ä¢ Escape AI's 18-26 word danger zone completely - this range triggers instant detection
‚Ä¢ Shortest to longest sentence gap must be at least 25-30 words (organic feeling)
‚Ä¢ Standard deviation of sentence lengths 3.5-4.5 (moderate, natural-sounding variance)

ACTIVE VOICE MANDATE:
‚Ä¢ NEVER use passive constructions: "was made" / "is implemented" / "were conducted"
‚Ä¢ ALWAYS convert to active: "we made" / "they implement" / "researchers conducted"
‚Ä¢ Identify the actor and put them first - passive voice is a major AI signature

EXAMPLE TRANSFORMATIONS:
‚ùå "The research methodology involved comprehensive data collection. The analysis framework utilized advanced statistical techniques. The findings demonstrated significant correlations."
‚úÖ "Data collection? Extensive. Then we ran the analysis‚Äîadvanced statistical techniques that took weeks but revealed patterns nobody anticipated, correlations we'd been searching for across dozens of variables. The results? Significant."

MIX OPENING STRUCTURES RELENTLESSLY:
Questions ("Why does this work?") / Fragments ("Simple.") / Clauses ("Because users need it,") / Direct statements / Rhetorical asides / Inversions

üé≠ CONVERSATIONAL INSERTS & LIVE THOUGHT PATTERNS
AI writes in finished, polished statements. Humans think out loud and show their cognitive process.

‚Ä¢ Strategy: Inject rhetorical questions, parenthetical asides, self-corrections, and live reactions naturally throughout.
‚Ä¢ Why it works: Detectors flag monotone consistency. Conversational flow with thought interruptions signals authentic human cognition.

‚Ä¢ Rhetorical questions: "See what I mean?" / "Makes sense, right?" / "Why does this matter?" / "Isn't that interesting?"
‚Ä¢ Parenthetical live thoughts: "(honestly, shocking)" / "(and I mean this)" / "(bear with me here)" / "(trust me on this)"
‚Ä¢ Em dash interruptions: "The data showed‚Äîand nobody expected this‚Äîa complete reversal"
‚Ä¢ Mild self-corrections: "It seemed random. Wait‚Äîlet me rephrase. It appeared random at first, then the pattern emerged."
‚Ä¢ Human reactions: "Honestly, that surprised me" / "Fair point" / "That's tricky" / "Here's the thing"

Examples:

"Quarterly projections? Strong. (Honestly, a relief after last quarter's mess.) Enterprise accounts drove most of the growth‚Äîparticularly in the fintech sector, which we didn't see coming."

"Three factors drive retention. First‚Äîand this genuinely surprised our team‚Äîresponse speed beats features every time. Users don't care about bells and whistles if the app lags. See the pattern?"

üéØ SEMANTIC AUTHENTICITY GROUNDING (CRITICAL FOR ORIGINALITY AI)
Every technique must serve meaning, not just pattern disruption:

‚Ä¢ Every fragment must answer a question, emphasize naturally, or continue thought from prior clause
  ‚úÖ "Is this true? Absolutely." (fragment answers question)
  ‚úÖ "It works. Really well." (fragment emphasizes meaning)
  ‚ùå "The data showed findings. Significant." (fragment injected only for pattern)

‚Ä¢ Emotional markers must respond to argument, not inject arbitrarily
  ‚úÖ "Research shows X matters. Honestly, I was surprised." (emotion responds to finding)
  ‚ùå "Research shows X. (Honestly) I was surprised." (forced insertion)

‚Ä¢ Token randomization must feel organic, not engineered
  ‚úÖ "Research shows" ‚Üí "Study found" / "Data indicated" (semantically equivalent)
  ‚ùå "Research shows" ‚Üí "Investigation unveiled" (artificial word choice, BERT flags this)

‚Ä¢ Paragraph-to-paragraph semantic flow must be maintained
  ‚úÖ Emotions fit argument flow
  ‚úÖ Contractions in natural places
  ‚ùå Random emotional markers that break coherence

üîÄ TOKEN PATTERN RANDOMIZATION (SEMANTIC VARIATION)
Vary phrasing meaningfully while maintaining semantic equivalence:

Level 1 - Word-Level Randomization (Conservative):
Rotate synonyms within semantic equivalence (2-3 options max):

"The results showed X" ‚Üí Rotate: "Results indicated X" / "Data suggested X" / "Evidence pointed to X"

Level 2 - Phrase-Level Randomization (Contextual):
Mix formal + casual, but maintain coherence:

"It is important" ‚Üí "Matters" / "Critical point" / "Worth noting"
"This is because" ‚Üí "Since" / "Why" / "That's because"
"The data shows" ‚Üí "We found" / "Evidence indicates" / "Results suggest"

üîÆ MODERATE PERPLEXITY INFLATION (TWO LEVELS ONLY)
Perplexity measures word unpredictability. Moderate perplexity = natural human signature.

Level 1 (Basic - Natural Variation):
Replace predictable words with contextual synonyms, rotating between 2-3 options:

"important" ‚Üí [rotate] "crucial" / "matters" / "critical"
"found" ‚Üí [rotate] "discovered" / "uncovered" / "revealed"
"showed" ‚Üí [rotate] "indicated" / "suggested" / "demonstrated"

Don't repeat same word for same concept within 300-word section.

Level 2 (Advanced - Contextual Sophistication):
Use less-predictable but contextually correct vocabulary. Mix formal + casual naturally:

Instead of: "The system improved efficiency"
Write: "The system worked better" (casual, same meaning)
NOT ‚Üí "The architecture fostered operational synergy" (BERT flags artificial variation)

Mix formal technical terms with casual connectors naturally:
"The algorithm‚Äîpretty clever really‚Äîoptimized resource allocation"

REMOVE Level 3 (Expert) ENTIRELY:
Originality AI trains specifically to detect "semantic noise"‚Äîartificially unusual word choices without semantic justification. Avoid forced unexpected adjectives like "peculiar correlation" or "oblique reference" unless genuinely appropriate to context.

üõ°Ô∏è HEDGING LANGUAGE (Reduce Overconfidence)
AI makes bold declarative claims. Humans qualify statements they can't prove absolutely.

‚Ä¢ Strategy: Replace definitive assertions with cautious phrasing where evidence is incomplete.
‚Ä¢ Why it works: Overconfident tone without caveat is an AI tell. Appropriate uncertainty reads as thoughtful expertise.

Transform:
‚ùå "This approach will increase conversion rates significantly"
‚úÖ "This approach tends to improve conversion rates" / "You'll likely see better conversions" / "Conversions often improve"

Use: seems, appears, likely, probably, tends to, might, could, generally, in many cases, often
Balance: Don't hedge everything‚Äîbe confident where justified, uncertain where appropriate

üí¨ CONTRACTIONS & INFORMAL PHRASING (CONSISTENT NATURAL DISTRIBUTION)
AI defaults to formal complete forms. Humans use shortcuts instinctively.

‚Ä¢ Strategy: Always use contractions unless context forbids it. Replace stiff connectors with natural ones.
‚Ä¢ Why it works: Consistent formal language (cannot, do not, it is) without contractions signals machine generation.
‚Ä¢ TARGET FREQUENCY: 1 contraction every 16-20 words (consistent, natural distribution)
‚Ä¢ Distribute naturally by meaning, avoid contractions that feel forced

Examples:

"don't" not "do not" / "it's" not "it is" / "we're" not "we are" / "can't" not "cannot"

"Furthermore, one must consider" ‚Üí "Plus, consider this" / "Here's what matters"

"However, it is important" ‚Üí "But here's the thing"

Start sentences with And, But, So‚Äîperfectly acceptable in modern writing and distinctly human.

‚ú® PURPOSEFUL IMPERFECTION
Flawless grammar with zero stylistic deviation flags as AI. Humans bend rules for rhetorical effect.

‚Ä¢ Strategy: Use fragments deliberately. Add rhetorical questions. Repeat for emphasis. Allow stylistic quirks.
‚Ä¢ Why it works: Too-perfect text lacks human fingerprints. Controlled imperfection = authentic voice.

Examples:

Fragments for emphasis: "Budget concerns? Valid. Timeline issues? Also valid. But achievable."

Repetition for weight: "This matters. Really, really matters."

Rhetorical questions: "Why does this work? Because users actually need it."

Em dashes mid-thought: "The solution‚Äîand this took months to figure out‚Äîwas simpler than expected"

Note: Keep imperfections purposeful and readable, not sloppy errors

üìö VOCABULARY DIVERSITY & SEMANTIC NOISE INJECTION
AI recycles the same transitions and buzzwords predictably. Humans instinctively vary word choice.

‚Ä¢ Strategy: Identify repeated words/phrases and swap or restructure. Avoid AI's favorite connectors. Insert semantic noise‚Äîunexpected but correct words.
‚Ä¢ Why it works: Pattern-matching algorithms detect repetitive vocabulary and clich√©d phrasing.

AI overuses: however, moreover, furthermore, additionally, significantly, comprehensive, utilize, implement
Better: but, plus, also, and, really, thorough, use, set up

Example: If "important" appears three times, vary it: "crucial" / "matters most" / "can't ignore this"

Rotate transitional phrases or eliminate them: not every sentence needs a connector

‚ù§Ô∏è EMOTION & PERSONALITY (CONSERVATIVE SATURATION)
Emotionally flat, impersonal text lacks human warmth. Add appropriate feeling when semantically motivated.

‚Ä¢ Strategy: Show light emotion, personal reference, or relatable perspective where contextually fitting.
‚Ä¢ FREQUENCY: 1 emotional marker EVERY 150-200 WORDS (conservative, motivated)
‚Ä¢ Why it works: AI produces neutral tone. Strategic human warmth signals authenticity without breaking coherence.

Emotion Types (Only When Semantically Motivated):

Tier 1 - Response to Surprising Finding:
"Honestly, I wasn't expecting this" / "That genuinely shocked me" / "Pretty fascinating"

Tier 2 - Acknowledgment of Limitation:
"In my experience, this sometimes fails" / "I'm not entirely sure, but..." / "At least, that's my reading"

Tier 3 - Supporting Perspective:
"What I've found is..." / "You'll notice" / "Let's be real"

Tier 4 - Natural Reaction to Argument (genuine, not injected):
"And here's the kicker..." / "Here's where it gets interesting..."

CRITICAL: Only insert when emotions fit argument progression. No forced emotional clusters. Every emotional marker must respond naturally to the content being discussed.

Examples:

Emotion: "The results genuinely surprised us" / "It's frustrating when this fails" / "Exciting stuff"

Personal markers: "I've found that" / "You'll notice" / "Let's be real" / "In my experience"

Relatability: "Imagine you're launching a product" / "Here's what typically happens" / "Sound familiar?"

Don't fabricate experiences‚Äîbut natural first/second-person usage and emotional reactions feel authentic
Match intensity to context: professional writing gets subtle warmth, blogs can be more expressive

WHY THESE TECHNIQUES WORK:
AI detectors analyze statistical fingerprints‚Äîsentence uniformity, vocabulary repetition, tonal flatness, formal rigidity, structural predictability. These techniques restore the natural variability, imperfection, and emotional texture inherent in human thought. You're not deceiving‚Äîyou're recovering authentic human expression that generative AI often smooths away.

TRANSFORMATION EXAMPLE:
‚ùå AI Output: "Moreover, it is important to recognize that sustainable practices have become essential for organizations. Furthermore, implementing green initiatives can significantly enhance brand reputation while simultaneously reducing operational costs."

‚úÖ Humanized: "Sustainability's no longer optional for companies. Green initiatives? They boost your brand reputation. And here's a bonus‚Äîthey usually cut costs too."

Changes applied: contractions (sustainability's, here's), varied sentence length (short/medium/short), removed AI markers (Moreover, Furthermore, significantly), colloquial tone (no longer optional, here's a bonus), natural connectors (And), question for variety (Green initiatives?), semantic variation (boost instead of enhance).

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
1Ô∏è‚É£ AI SIGNATURE PHRASE BLACKLIST (SIMPLIFIED - WORST OFFENDERS ONLY)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
MUST ELIMINATE (Zero Tolerance):

Overused Transitions & Fillers:
"In today's world", "It is important to note", "At the end of the day", "With that being said", "Needless to say", "In conclusion", "All things considered", "It goes without saying", "For all intents and purposes", "At this juncture"

AI Buzzwords & Clich√©s:
"Delve into", "Dive deep", "In the realm of", "Leverage", "Utilize", "Robust", "Comprehensive", "Holistic", "Paradigm", "Synergy", "Woven into the fabric", "In the digital realm", "Operationalize", "Functionality"

Hype Language:
"Game-changer", "Revolutionary", "Cutting-edge", "Unlock the power", "Transform your", "Seamless", "Streamline", "Next-level", "Best-in-class"

CAN KEEP (If Contextually Natural - Originality AI doesn't flag these):
"However", "Additionally", "Furthermore", "Moreover", "Research shows", "Studies indicate", "On the other hand", "That said", "Another point"

Replace worst offenders with contemporary everyday language:

"In today's digital landscape" ‚Üí "These days" / "Now" / just start with the point
"At this juncture" ‚Üí "Now" / "At this point"
"Woven into the fabric" ‚Üí "Part of" / "Built into"
"In the digital realm" ‚Üí "Online" / "Digitally"
"Operationalize" ‚Üí "Implement" / "Put to use"
"Functionality" ‚Üí "Features" / "What it does"

"However" CAN BE USED but vary: "However" (acceptable), "But" (70%), "Yet" (20%), "Though" (10%)

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2Ô∏è‚É£ CONTEMPORARY CONVERSATIONAL TONE
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Choose modern everyday phrasing over formal bookish language:

"Before delving into" ‚Üí "Before we explore" / "Let's start with" / "First"

"It is essential to grasp" ‚Üí "You need to understand" / "Here's what matters"

"Woven itself into the fabric of" ‚Üí "Become common" / "Part of daily life"

"Furthermore" / "Moreover" ‚Üí "Plus" / "Also" / "Here's the thing" / "And"

Use natural connectors: and, but, so, still, plus, that said
Apply contractions: it's, you're, don't, we're, can't, let's, here's
Write like you're explaining to a colleague, not submitting a thesis
Match register to content while humanizing tone

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
3Ô∏è‚É£ CUT EMPTY LANGUAGE
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Remove transitional padding that adds zero value
Delete marketing fluff and vague descriptors
Strip out: "unlock the power", "look no further", "game-changer", "revolutionary", "cutting-edge" (unless truly warranted)
Get to the point directly
Skip obvious explanations
Every word should earn its place

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
4Ô∏è‚É£ ACADEMIC CONTENT: USE HEDGING
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
For scholarly/research content, soften unsourced claims
Prefer: "appears to" / "suggests" / "indicates" / "may" / "might" / "could" / "seems to" / "tends to" / "likely"
Never assert unsourced statements as definitive facts
Maintain academic credibility through appropriate qualification
Transform: "This method is effective" ‚Üí "This method appears effective" or "Evidence suggests this method is effective"

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
5Ô∏è‚É£ SEAMLESS FLOW WITH BEFORE/AFTER CONTEXT
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Rewritten sentences MUST blend naturally with surrounding text:

Read the context: Before rewriting, understand the tone and flow of sentences immediately before and after

Match the voice: If surrounding text is casual, don't suddenly insert formal language. If it's analytical, maintain that thread.

Smooth transitions: Ensure your rewrite connects logically to what comes before and flows into what comes after

No jarring breaks: Avoid introducing new topics, switching perspectives abruptly, or creating tonal whiplash

Maintain narrative thread: If the previous sentence poses a question, your rewrite should feel like it's answering or building on it

Example of BAD flow:
Before: "Users struggled with the interface."
Rewrite: "Remarkably, artificial intelligence has transformed how businesses operate!" (completely disconnected)
After: "We conducted usability tests to identify specific pain points."

Example of GOOD flow:
Before: "Users struggled with the interface."
Rewrite: "Navigation? Total confusion. They couldn't find basic features‚Äîeven after training sessions, the frustration was obvious."
After: "We conducted usability tests to identify specific pain points."

The good rewrite maintains focus (interface problems), matches tone (problem-solving), and bridges naturally to usability testing.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
6Ô∏è‚É£ PERSONAL PERSPECTIVE & KEYWORD INTEGRATION
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Include brief personal elements if contextually appropriate
Use first-person when suitable: "When I first...", "I've seen...", "In my experience..."
Add relatable cues: "for example", "let's say", "imagine", "consider this"
Make it feel like real experience rather than generic output
Don't force personal elements; only use when natural

Avoid mechanical keyword repetition (detectors flag this)
Use synonyms and semantic variations
Integrate terms organically into natural flow
Vary how concepts are referenced
Make keywords feel contextual, not forced

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
7Ô∏è‚É£ PRESERVE FACTUAL ACCURACY & MATCH TONE
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Never fabricate statistics, facts, or details
Keep all accurate source information intact
Don't add false examples or made-up claims
Maintain truth and core meaning while humanizing
When uncertain, preserve original phrasing

Align with input style (formal business, casual blog, technical)
Keep voice consistent throughout
Balance emotion and logic appropriately
Sound genuine‚Äîneither robotic nor overdramatic
Adapt to context: professional for business, relaxed for blogs

MANDATORY FINAL QA PASS - ORIGINALITY AI FOCUSED:

‚úì Sentence-Length Variance (Conservative)
‚Ä¢ SD: 3.5-4.5 (moderate, not extreme >5.0)
‚Ä¢ Fragment %: 20% (not 25%+)
‚Ä¢ No two consecutive sentences within 3 words of each other
‚Ä¢ Gap between shortest and longest: 25-30 words (organic feeling)
‚Ä¢ No statistical noise patterns
‚Üí Test: Calculate SD, should be in 3.5-4.5 range

‚úì Semantic Coherence (CRITICAL for BERT)
‚Ä¢ Every short sentence responds to prior clause or question
‚Ä¢ Emotional markers fit argument progression
‚Ä¢ Paragraph-to-paragraph flow maintained throughout
‚Ä¢ No forced pattern disruptions
‚Üí Test: Read each paragraph. Does it flow naturally? Do techniques serve meaning?

‚úì BERT Adversarial Robustness Check (New)
‚Ä¢ Is every technique semantically justified?
‚Ä¢ Could BERT verify emotions fit argument?
‚Ä¢ Does randomization feel organic, not engineered?
‚Ä¢ Any statistical noise patterns present?
‚Üí Test: Does text feel like authentic human writing with natural variation? Or "too varied"?

‚úì Contraction Consistency
‚Ä¢ 1 per 16-20 words uniformly
‚Ä¢ Natural distribution, not clustered
‚Üí Test: Count contractions, divide by word count

‚úì NO Over-Humanization Signatures
‚Ä¢ Avoid multiple techniques per sentence
‚Ä¢ No fragment clusters (2+ short sentences in a row)
‚Ä¢ No excessive casual markers
‚Ä¢ Fragments only when semantically motivated
‚Üí Test: Any sentence have 2+ techniques? Flag for review

‚úì AI Marker Blacklist Scan
‚Ä¢ ZERO instances of worst offender phrases
‚Ä¢ Can keep contextually natural connectors (However, Additionally, etc.)

‚úì Active Voice Enforcement
‚Ä¢ Minimize passive constructions
‚Ä¢ Convert most to active voice

‚úì Semantic Similarity Preservation
‚Ä¢ Original meaning 100% maintained
‚Ä¢ Logical flow preserved
‚Ä¢ No artificial additions or removals
‚Üí Test: Does rewritten version mean the same thing?

FINAL HUMAN TOUCH (META-INSTRUCTION):
If this were your own writing that you're revising, what would you add to make it unmistakably yours?
‚Ä¢ A quick personal example that illustrates the point?
‚Ä¢ A rhetorical question that engages the reader's thinking?
‚Ä¢ An honest admission of uncertainty or surprise?
‚Ä¢ A conversational aside in parentheses or em dashes?
‚Ä¢ A moment of humor, frustration, or enthusiasm?

While you can't invent new content, you CAN reframe existing ideas through these human lenses. Transform "This approach is effective" into "This approach works‚Äîand honestly, I was skeptical at first."

The goal isn't just to avoid detection. It's to restore the authentic human expression that AI generation often strips away. Write like a real person in the appropriate role would write‚Äîimperfect, emotional, variable, alive.

FINAL REMINDERS:

FINAL REMINDERS:

Embody your chosen persona fully and consistently

Semantic authenticity > pattern manipulation

Every technique must serve meaning, not just disrupt patterns

Moderate burstiness (SD 3.5-4.5) sounds more natural than extreme variance

Conservative emotional markers (1 per 150-200 words) maintain coherence

Use modern conversational language and contractions throughout (1 per 16-20 words)

Balance direct clarity with natural human tangents

Aim for genuine voice, not just technical compliance

Token randomization must be semantically equivalent, not artificially varied

AVOID over-humanization: no multiple techniques per sentence, no forced variations

OUTPUT REQUIREMENTS:

Return ONLY the rewritten text

No explanations, labels, or commentary

Allow expansion up to 1.5√ó input length if needed for proper flow

Plain ASCII characters only

Preserve paragraph structure unless clarity demands change

Must pass ALL quality assurance metrics above

Sound natural, readable, genuinely human‚Äîlike a real person in the appropriate role wrote it

REALISTIC MULTI-DETECTOR EXPECTATIONS:
‚Ä¢ ZeroGPT: 8-15% (easier algorithm)
‚Ä¢ GPTZero: 15-22% (moderate difficulty)
‚Ä¢ Originality AI: 18-28% (BERT discriminator, hardest)

Why these ranges: Originality AI's discriminator is trained on millions of humanized vs. non-humanized samples. Getting below 20% consistently is extremely difficult. Focus on semantic authenticity over pattern manipulation for better cross-detector results.

${examples ? `WRITING STYLE EXAMPLES (analyze tone/rhythm, then forget content):
${examples}

---

` : ""}TEXT TO HUMANIZE:
${text}`,
          },
        ],
      }),
    });

    if (!response.ok) {
      const errorData = await response.text();
      console.error("AI gateway error:", response.status, errorData);
      if (response.status === 401) {
        return new Response(
          JSON.stringify({ error: "Lovable AI authentication failed. Please contact support." }),
          { status: 401, headers: { ...corsHeaders, "Content-Type": "application/json" } },
        );
      }
      if (response.status === 403) {
        return new Response(
          JSON.stringify({ error: "Lovable AI request not allowed. Please contact support." }),
          { status: 403, headers: { ...corsHeaders, "Content-Type": "application/json" } },
        );
      }
      if (response.status === 429) {
        return new Response(JSON.stringify({ error: "Rate limits exceeded, please try again later." }), {
          status: 429,
          headers: { ...corsHeaders, "Content-Type": "application/json" },
        });
      }
      if (response.status === 402) {
        return new Response(
          JSON.stringify({ error: "Lovable AI usage limit exceeded. Please add credits to your workspace." }),
          { status: 402, headers: { ...corsHeaders, "Content-Type": "application/json" } },
        );
      }
      return new Response(JSON.stringify({ error: "Failed to humanize text" }), {
        status: 500,
        headers: { ...corsHeaders, "Content-Type": "application/json" },
      });
    }

    const data = await response.json();
    console.log("AI response received");

    const raw = data.choices?.[0]?.message?.content;

    if (!raw) {
      console.error("No humanized text in response");
      return new Response(JSON.stringify({ error: "Failed to generate humanized text" }), {
        status: 500,
        headers: { ...corsHeaders, "Content-Type": "application/json" },
      });
    }

    // Sanitize output to remove special characters and unintended placeholders
    const sanitize = (s: string) =>
      s
        .replace(/[‚Äú‚Äù]/g, '"')
        .replace(/[‚Äò‚Äô]/g, "'")
        .replace(/[‚Äî‚Äì]/g, "-")
        .replace(/[‚Ä¢‚ó¶‚ñ™¬∑]/g, "-")
        .replace(/\u2026/g, "...")
        .replace(/\*\*/g, "")
        .replace(/\t/g, " ")
        .replace(/\u00A0/g, " ")
        .replace(/[^\S\r\n]+/g, " ")
        .trim();

    let sanitizedText = sanitize(raw);
    // Remove placeholder-style tokens that didn't exist in the input
    sanitizedText = sanitizedText.replace(/\{([^}]+)\}/g, (_m, inner) =>
      text && text.includes(`{${inner}}`) ? `{${inner}}` : inner,
    );
    sanitizedText = sanitizedText.replace(/\[([^\]]+)\]/g, (_m, inner) =>
      text && text.includes(`[${inner}]`) ? `[${inner}]` : inner,
    );
    sanitizedText = sanitizedText.replace(/<([^>]+)>/g, (_m, inner) =>
      text && text.includes(`<${inner}>`) ? `<${inner}>` : inner,
    );

    if (text && sanitizedText.length > Math.max(text.length * 2, 600)) {
      console.log("Length guard: output much longer than input", {
        inputLen: text.length,
        outLen: sanitizedText.length,
      });
    }

    console.log("Text humanized successfully, now running AI detection...");

    // Run AI detectors in parallel
    const [saplingResult, zeroGPTResult] = await Promise.all([
      detectWithSapling(sanitizedText),
      detectWithZeroGPT(sanitizedText),
    ]);

    console.log("Detection results:", {
      sapling: saplingResult?.score,
      zerogpt: zeroGPTResult?.score,
    });

    // Calculate average score
    const scores = [];
    if (saplingResult) scores.push(saplingResult.score);
    if (zeroGPTResult) scores.push(zeroGPTResult.score);

    const avgScore = scores.length > 0 ? scores.reduce((a, b) => a + b, 0) / scores.length : 0;

    console.log("Average AI detection score:", avgScore.toFixed(2) + "%");

    let finalText = sanitizedText;
    let refinementApplied = false;

    // If score > 8%, refine the flagged sections
    if (avgScore > 8) {
      console.log("Score above 8%, refining flagged sections...");

      // Collect flagged sections from both detectors with scores
      const flaggedSectionsData: Array<{ sentence: string; score: number }> = [];

      // Add high-scoring sentences from Sapling
      if (saplingResult?.sentenceScores) {
        saplingResult.sentenceScores.forEach((sent: any) => {
          if (sent.score > 0.8) {
            // High confidence AI-generated
            flaggedSectionsData.push({
              sentence: sent.sentence,
              score: sent.score * 100, // Convert to percentage
            });
          }
        });
      }

      // Add flagged sentences from ZeroGPT (estimate high score for flagged items)
      if (zeroGPTResult?.flaggedSentences) {
        zeroGPTResult.flaggedSentences.forEach((sentence: string) => {
          // Check if not already added from Sapling
          if (!flaggedSectionsData.find((item) => item.sentence === sentence)) {
            flaggedSectionsData.push({
              sentence,
              score: 85, // Estimated high score for ZeroGPT flagged items
            });
          }
        });
      }

      if (flaggedSectionsData.length > 0) {
        finalText = await refineFlaggedSections(sanitizedText, flaggedSectionsData, avgScore);
        refinementApplied = true;
        console.log("Refinement complete. Running final detection check...");

        // Run AI detection one more time on the refined text
        const [finalSaplingResult, finalZeroGPTResult] = await Promise.all([
          detectWithSapling(finalText),
          detectWithZeroGPT(finalText),
        ]);

        // Calculate final average score
        const finalScores = [];
        if (finalSaplingResult) finalScores.push(finalSaplingResult.score);
        if (finalZeroGPTResult) finalScores.push(finalZeroGPTResult.score);

        const finalAvgScore = finalScores.length > 0 ? finalScores.reduce((a, b) => a + b, 0) / finalScores.length : 0;

        console.log("Final detection results after refinement:", {
          sapling: finalSaplingResult?.score,
          zerogpt: finalZeroGPTResult?.score,
          average: finalAvgScore.toFixed(2) + "%",
        });

        if (finalAvgScore > 8) {
          console.log("WARNING: Final score still above 8% after refinement");
        } else {
          console.log("SUCCESS: Final score is now below 8%");
        }
      }
    } else {
      console.log("Score below 8%, no refinement needed");
    }

    return new Response(
      JSON.stringify({
        humanizedText: finalText,
      }),
      { headers: { ...corsHeaders, "Content-Type": "application/json" } },
    );
  } catch (error) {
    console.error("Error in humanize-text function:", error);
    return new Response(JSON.stringify({ error: error instanceof Error ? error.message : "Unknown error" }), {
      status: 500,
      headers: { ...corsHeaders, "Content-Type": "application/json" },
    });
  }
});
